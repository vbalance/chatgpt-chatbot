{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYYuG/c4PiM1H5H+KM3CDS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/All-About-AI-YouTube/ChatGPT-ChatBot/blob/main/ChatGPT_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH3tmrywpDan",
        "outputId": "81d72fa6-819f-488e-a996-bdf4b4e644c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai\n",
        "\n",
        "!pip install -q requests\n",
        "\n",
        "import openai\n",
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to open a file and return its contents as a string\n",
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "#   Define a function to save content to a file\n",
        "def save_file(filepath, content):\n",
        "    with open(filepath, 'a', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "# Set the OpenAI API key by reading it from a file\n",
        "openai.api_key = open_file('openaiapikey.txt')\n",
        "\n",
        "# Initialize an empty list to store the conversation\n",
        "conversation = []\n",
        "\n",
        "# Read the content of a file containing the chatbot's prompt\n",
        "chatbot = open_file('chatbot.txt')\n",
        "\n",
        "# Define a function to make an API call to the OpenAI ChatCompletion endpoint\n",
        "def chatgpt(user_input, temperature=0.8, frequency_penalty=0.2, presence_penalty=0):\n",
        "    global conversation # When a variable is declared as global within a function, it means that any changes made to the variable inside the function will also affect the value of the variable outside the function.\n",
        "\n",
        "    # Update conversation by appending the user's input\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Insert prompt/s into message history - By inserting the chatbot's prompt message into the conversation history before making an API call to the OpenAI ChatCompletion endpoint, the function ensures that the chatbot's response will be generated in the correct context and take into account any previous messages in the conversation history. This can improve the quality and relevance of the chatbot's responses.\n",
        "    messages_input = conversation.copy()\n",
        "    prompt = [{\"role\": \"system\", \"content\": chatbot}]\n",
        "    prompt_item_index = 0\n",
        "    for prompt_item in prompt:\n",
        "        messages_input.insert(prompt_item_index, prompt_item)\n",
        "        prompt_item_index += 1\n",
        "\n",
        "    # Make an API call to the ChatCompletion endpoint with the updated messages\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=temperature,\n",
        "        frequency_penalty=frequency_penalty,\n",
        "        presence_penalty=presence_penalty,\n",
        "        messages=messages_input)\n",
        "\n",
        "    # Extract the chatbot's response from the API response\n",
        "    chat_response = completion['choices'][0]['message']['content']\n",
        "\n",
        "    # Update conversation by appending the chatbot's response\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": chat_response})\n",
        "\n",
        "    # Return the chatbot's response\n",
        "    return chat_response\n",
        "\n",
        "# Enter an infinite loop to prompt the user for input and get the chatbot's response - This loop will continue running until it is manually interrupted or terminated by the user, allowing the user to have a conversation with the chatbot by entering messages as input and receiving the chatbot's responses in return.\n",
        "while True:\n",
        "    user_message = input(\"> \") # Prompt the user for input\n",
        "    response = (\"\\n\\n\") + chatgpt(user_message) + (\"\\n\\n\") # Call the chatgpt function with user input\n",
        "    print(response) # Print the chatbot's response\n",
        "    save_file(\"Chatlog.txt\", user_message + ('\\n\\n') + response + ('\\n\\n'))"
      ],
      "metadata": {
        "id": "5bmyfQMIpH6t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}